{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install timm","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting timm\n  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n\u001b[K     |████████████████████████████████| 244 kB 3.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (3.7.4.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (1.18.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (1.18.5)\nRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.0.1)\nInstalling collected packages: timm\nSuccessfully installed timm-0.3.2\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport argparse\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\n\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom collections import OrderedDict\nimport timm","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# store the path to the directories with preprocessed png images\ntrain_dir = '../input/siic-isic-224x224-images/train/'\ntest_dir = '../input/siic-isic-224x224-images/test/'\n\n# load csv files with image name and metadata\ntrain_df = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest_df = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Dataset and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set device to gpu if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Define the Dataset and the DataLoader\nclass MyDataset(Dataset):\n    def __init__(self, dataframe, train=True, transform=None):\n        self.df = dataframe\n        self.train = train\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_name = self.df['image_name'][idx]\n        \n        if self.train:\n            img_path = train_dir + img_name + '.png'\n        else:\n            img_path = test_dir + img_name + '.png'\n        \n        # read in the image\n        image = cv2.imread(img_path) # (224, 224, 3)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # reorder colors\n        image = transforms.ToPILImage()(image) \n            \n        if self.transform:\n            image = self.transform(image)\n          \n        if self.train:\n            label = self.df['target'][idx]\n            return image, label\n        else:\n            return image\n\n# TODO: add additional data augmentation\ndata_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\ntrainset = MyDataset(train_df, train=True, transform=data_transform)\ntestset = MyDataset(test_df, train=False, transform=test_transform)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a multilayer neural net"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_inputs = 150528 # 3 x 224 x 224 color images\nnum_outputs = 2\n\nclass MultiLayerNet(nn.Module):\n    def __init__(self, num_inputs, num_outputs, hidden_units):\n        super(MultiLayerNet, self).__init__()\n        self.linear1 = nn.Linear(num_inputs, hidden_units)\n        self.linear2 = nn.Linear(hidden_units, num_outputs)\n\n    def forward(self, input):\n        input = input.view(-1, num_inputs)\n        output = self.linear1(input)\n        output = torch.tanh(output)\n        output = self.linear2(output)\n        return output\n    \n##########################################################\n\nclass ConvolutionalNet(nn.Module):\n    def __init__(self, num_inputs, num_outputs):\n        super(ConvolutionalNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 5) # 3 channel, 16 feature maps, 5x5 square convolution\n        self.conv2 = nn.Conv2d(16, 128, 5) # 16 input, 128 output, 5x5 square convolution\n        \n        self.linear1 = nn.Linear(128 * 53 * 53, 64)  # 64 hidden units\n        self.linear2 = nn.Linear(64, num_outputs)  # 64 hidden units to 10 output units\n\n    def forward(self, input):\n        output = F.tanh(self.conv1(input))\n        output = F.max_pool2d(output, (2, 2))   # 2 by 2 max pooling (subsampling) \n        output = F.tanh(self.conv2(output))\n        output = F.max_pool2d(output, (2, 2))   # 2 by 2 max pooling (subsampling) \n        \n        # flatten to vector\n        output = output.view(-1, self.num_flat_features(output)) # flatten features\n        output = self.linear1(output)\n        output = F.tanh(output)\n        output = self.linear2(output)\n        return output\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Try a CNN architecture based off of LeNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a CNN based off of LeNet\n\n\nclass C1(nn.Module):\n    def __init__(self):\n        super(C1, self).__init__()\n\n        self.c1 = nn.Sequential(OrderedDict([\n            ('c1', nn.Conv2d(3, 6, kernel_size=(5, 5))),\n            ('relu1', nn.ReLU()),\n            ('s1', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n        ]))\n\n    def forward(self, img):\n        output = self.c1(img)\n        return output\n\n\nclass C2(nn.Module):\n    def __init__(self):\n        super(C2, self).__init__()\n\n        self.c2 = nn.Sequential(OrderedDict([\n            ('c2', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n            ('relu2', nn.ReLU()),\n            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n        ]))\n\n    def forward(self, img):\n        output = self.c2(img)\n        return output\n\n\nclass C3(nn.Module):\n    def __init__(self):\n        super(C3, self).__init__()\n\n        self.c3 = nn.Sequential(OrderedDict([\n            ('c3', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n            ('relu3', nn.ReLU())\n        ]))\n\n    def forward(self, img):\n        output = self.c3(img)\n        return output\n\n\nclass F4(nn.Module):\n    def __init__(self):\n        super(F4, self).__init__()\n\n        self.f4 = nn.Sequential(OrderedDict([\n            ('f4', nn.Linear(120*49*49, 84)),\n            ('relu4', nn.ReLU())\n        ]))\n\n    def forward(self, img):\n        output = self.f4(img)\n        return output\n\n\nclass F5(nn.Module):\n    def __init__(self):\n        super(F5, self).__init__()\n\n        self.f5 = nn.Sequential(OrderedDict([\n            ('f5', nn.Linear(84, 2))  # \n        ]))\n\n    def forward(self, img):\n        output = self.f5(img)\n        return output\n\n\nclass LeNet(nn.Module):\n    \"\"\"\n    Input - 3x224x224\n    Output - 2\n    \"\"\"\n    def __init__(self):\n        super(LeNet, self).__init__()\n\n        self.c1 = C1()\n        self.c2_1 = C2() \n        self.c2_2 = C2() \n        self.c3 = C3() \n        self.f4 = F4() \n        self.f5 = F5() \n\n    def forward(self, img):\n        output = self.c1(img)\n\n        x = self.c2_1(output)\n        output = self.c2_2(output)\n\n        output += x\n\n        output = self.c3(output)\n        # flatten to a vector\n        output = output.view(-1, self.num_flat_features(output)) # flatten features\n        output = self.f4(output)\n        output = self.f5(output)\n        return output\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use EfficientNet for pretraining and then finetune\n\nhttps://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n\n- Initialize the pretrained model\n- Reshape the final layer(s) to have the same number of outputs as the number of classes in the new dataset\n- Define for the optimization algorithm which parameters we want to update during training\n- Run the training step"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Use pretrained Resnet\n# network = models.resnet18(pretrained=True)\n# network.fc = nn.Linear(512, 2)   # replace the last fully connected layer\n\n# # check if CUDA is available\n# train_on_gpu = torch.cuda.is_available()\n\n# if train_on_gpu:\n#     network.cuda()","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the neural network model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(network, epoch, train_loader, verbose=True):\n    network.train()\n    losses = []\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = network(data)\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if verbose and batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n        losses.append(loss.item())   # add the loss of each batch\n    return losses\n\ndef test(network, train_loader):\n    network.eval()\n    test_loss = 0\n    correct = 0\n    probs = np.zeros((len(train_loader.dataset)))\n    targets = np.zeros((len(train_loader.dataset)))\n    \n    for i, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        \n        output = network(data)\n        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        \n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n        prob = F.softmax(output, 1)[:, 1].cpu().detach().numpy()\n        probs[i*batch_size:(i+1)*batch_size] = prob\n        targets[i*batch_size:(i+1)*batch_size] = target.cpu().detach().numpy()\n\n    test_loss /= len(train_loader.dataset)\n    \n    roc = roc_auc_score(targets, probs)\n    \n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), AUROC: {:.4f}\\n'.format(\n        test_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset), roc))\n    return test_loss, 100. * correct / len(train_loader.dataset), roc","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# batch_size = 32\n# img_size = (224, 224)\n# epochs = 10       # number of epochs to train\n# lr = 0.001        # learning rate\n\n# # load data\n# train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n# test_loader  = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# # reset model\n# # network = MultiLayerNet(num_inputs, num_outputs, hidden_units=1000)\n# # network = ConvolutionalNet(num_inputs, num_outputs)\n# # network = LeNet()\n\n# # Use a pretrained EfficientNet\n# network = timm.create_model('tf_efficientnet_b2_ns', \n#                           pretrained=True, \n#                           num_classes=2)\n\n\n# # check if CUDA is available\n# train_on_gpu = torch.cuda.is_available()\n# if train_on_gpu:\n#     network.cuda()\n\n# # TODO: also try AdamW optimizer and dynamic learning rate\n# optimizer = optim.SGD(network.parameters(), lr=lr)\n\n# train_losses = []\n# for epoch in range(epochs):\n#     train_loss = train(network, epoch, train_loader)\n#     train_losses += train_loss\n\n# # display the decreasing training loss\n# plt.plot(train_losses)\n# # test_loss, test_acc = test(test_loader)  # print the validation error\n# # plt.hlines(test_loss, 0, len(train_losses), color='r', label='Test Loss')\n# plt.legend(loc='upper right')\n# plt.title('Training Loss over Epochs')","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying Stratified KFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nbatch_size = 32\nimg_size = (224, 224)\nepochs = 10       # number of epochs to train\nlr = 0.001        # learning rate\n\nskf = StratifiedKFold(5, shuffle=True, random_state=0)\nfold = 0\nrocs = []\n\nfor train_index, test_index in skf.split(train_df['image_name'], train_df['target']):\n    if fold == 0:\n        train_single = train_index\n        test_single = test_index\n    \n    fold += 1\n    print(\"Fold: \", fold)\n    PATH = \"enet{}.pt\".format(fold)\n    \n    # node that the testset here is actually the validation set\n    train_rows = train_df.loc[train_index]\n    test_rows = train_df.loc[test_index]\n    train_rows.reset_index(drop=True, inplace=True)\n    test_rows.reset_index(drop=True, inplace=True)\n    \n    # set up data\n    trainset = MyDataset(train_rows, train=True, transform=data_transform)\n    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    # note that the testset here does include labels because it's the validation set\n    testset = MyDataset(test_rows, train=True, transform=test_transform)\n    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n   \n    # set up model\n    network = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\n    train_on_gpu = torch.cuda.is_available()\n    if train_on_gpu:\n        network.cuda()\n        \n    optimizer = optim.SGD(network.parameters(), lr=lr)\n    best_roc = 0\n    counter = 0\n    \n    # train model\n    for epoch in range(epochs):\n        train_loss = train(network, epoch, train_loader)\n        # print(\"Train loss: \", train_loss)\n        \n        # TODO: try early stopping\n        test_loss, test_acc, test_roc = test(network, test_loader)\n        print(\"Eval loss: \", test_loss)\n        print(\"Eval AUROC: \", test_roc)\n        if test_roc >= best_roc:\n            best_roc = test_roc\n            torch.save(network.state_dict(), PATH)  # save the state of the best model so far\n        else:\n            counter += 1\n            if counter > 1:\n                print('No improvement in ROC for two consecutive epochs')\n                break\n    print(\"Best AUROC: \", best_roc)\n    rocs.append(best_roc)\n    \n    ","execution_count":null,"outputs":[{"output_type":"stream","text":"Fold:  1\nTrain Epoch: 0 [0/26500 (0%)]\tLoss: 2.200136\nTrain Epoch: 0 [3200/26500 (12%)]\tLoss: 0.376369\nTrain Epoch: 0 [6400/26500 (24%)]\tLoss: 0.100226\nTrain Epoch: 0 [9600/26500 (36%)]\tLoss: 0.152626\nTrain Epoch: 0 [12800/26500 (48%)]\tLoss: 0.092195\nTrain Epoch: 0 [16000/26500 (60%)]\tLoss: 0.007857\nTrain Epoch: 0 [19200/26500 (72%)]\tLoss: 0.016647\nTrain Epoch: 0 [22400/26500 (84%)]\tLoss: 0.727773\nTrain Epoch: 0 [25600/26500 (97%)]\tLoss: 0.650863\nTrain Epoch: 1 [0/26500 (0%)]\tLoss: 0.022962\nTrain Epoch: 1 [3200/26500 (12%)]\tLoss: 0.012848\nTrain Epoch: 1 [6400/26500 (24%)]\tLoss: 0.194198\nTrain Epoch: 1 [9600/26500 (36%)]\tLoss: 0.393200\nTrain Epoch: 1 [12800/26500 (48%)]\tLoss: 0.888061\nTrain Epoch: 1 [16000/26500 (60%)]\tLoss: 0.033129\nTrain Epoch: 1 [19200/26500 (72%)]\tLoss: 0.183562\nTrain Epoch: 1 [22400/26500 (84%)]\tLoss: 0.011540\nTrain Epoch: 1 [25600/26500 (97%)]\tLoss: 0.003465\nTrain Epoch: 2 [0/26500 (0%)]\tLoss: 0.023933\nTrain Epoch: 2 [3200/26500 (12%)]\tLoss: 0.018774\nTrain Epoch: 2 [6400/26500 (24%)]\tLoss: 0.112241\nTrain Epoch: 2 [9600/26500 (36%)]\tLoss: 0.013861\nTrain Epoch: 2 [12800/26500 (48%)]\tLoss: 0.126773\nTrain Epoch: 2 [16000/26500 (60%)]\tLoss: 0.011761\nTrain Epoch: 2 [19200/26500 (72%)]\tLoss: 0.109477\nTrain Epoch: 2 [22400/26500 (84%)]\tLoss: 0.012320\nTrain Epoch: 2 [25600/26500 (97%)]\tLoss: 0.356006\nTrain Epoch: 3 [0/26500 (0%)]\tLoss: 0.009146\nTrain Epoch: 3 [3200/26500 (12%)]\tLoss: 0.022489\nTrain Epoch: 3 [6400/26500 (24%)]\tLoss: 0.036638\nTrain Epoch: 3 [9600/26500 (36%)]\tLoss: 0.169052\nTrain Epoch: 3 [12800/26500 (48%)]\tLoss: 0.155395\nTrain Epoch: 3 [16000/26500 (60%)]\tLoss: 0.014488\nTrain Epoch: 3 [19200/26500 (72%)]\tLoss: 0.086947\nTrain Epoch: 3 [22400/26500 (84%)]\tLoss: 0.010482\nTrain Epoch: 3 [25600/26500 (97%)]\tLoss: 0.021382\nTrain Epoch: 4 [0/26500 (0%)]\tLoss: 0.274880\nTrain Epoch: 4 [3200/26500 (12%)]\tLoss: 0.215539\nTrain Epoch: 4 [6400/26500 (24%)]\tLoss: 0.007376\nTrain Epoch: 4 [9600/26500 (36%)]\tLoss: 0.006771\nTrain Epoch: 4 [12800/26500 (48%)]\tLoss: 0.160906\nTrain Epoch: 4 [16000/26500 (60%)]\tLoss: 0.014832\nTrain Epoch: 4 [19200/26500 (72%)]\tLoss: 0.145414\nTrain Epoch: 4 [22400/26500 (84%)]\tLoss: 0.026664\nTrain Epoch: 4 [25600/26500 (97%)]\tLoss: 0.007884\nTrain Epoch: 5 [0/26500 (0%)]\tLoss: 0.013865\nTrain Epoch: 5 [3200/26500 (12%)]\tLoss: 0.109373\nTrain Epoch: 5 [6400/26500 (24%)]\tLoss: 0.079430\nTrain Epoch: 5 [9600/26500 (36%)]\tLoss: 0.014762\nTrain Epoch: 5 [12800/26500 (48%)]\tLoss: 0.450293\nTrain Epoch: 5 [16000/26500 (60%)]\tLoss: 0.008329\nTrain Epoch: 5 [19200/26500 (72%)]\tLoss: 0.007985\nTrain Epoch: 5 [22400/26500 (84%)]\tLoss: 0.071375\nTrain Epoch: 5 [25600/26500 (97%)]\tLoss: 0.028889\nTrain Epoch: 6 [0/26500 (0%)]\tLoss: 0.156892\nTrain Epoch: 6 [3200/26500 (12%)]\tLoss: 0.447007\nTrain Epoch: 6 [6400/26500 (24%)]\tLoss: 0.574150\nTrain Epoch: 6 [9600/26500 (36%)]\tLoss: 0.005017\nTrain Epoch: 6 [12800/26500 (48%)]\tLoss: 0.013759\nTrain Epoch: 6 [16000/26500 (60%)]\tLoss: 0.394189\nTrain Epoch: 6 [19200/26500 (72%)]\tLoss: 0.007395\nTrain Epoch: 6 [22400/26500 (84%)]\tLoss: 0.012472\nTrain Epoch: 6 [25600/26500 (97%)]\tLoss: 0.278413\nTrain Epoch: 7 [0/26500 (0%)]\tLoss: 0.255415\nTrain Epoch: 7 [3200/26500 (12%)]\tLoss: 0.213582\nTrain Epoch: 7 [6400/26500 (24%)]\tLoss: 0.010626\nTrain Epoch: 7 [9600/26500 (36%)]\tLoss: 0.191264\nTrain Epoch: 7 [12800/26500 (48%)]\tLoss: 0.002211\nTrain Epoch: 7 [16000/26500 (60%)]\tLoss: 0.166405\nTrain Epoch: 7 [19200/26500 (72%)]\tLoss: 0.004092\nTrain Epoch: 7 [22400/26500 (84%)]\tLoss: 0.040557\nTrain Epoch: 7 [25600/26500 (97%)]\tLoss: 0.010017\nTrain Epoch: 8 [0/26500 (0%)]\tLoss: 0.034862\nTrain Epoch: 8 [3200/26500 (12%)]\tLoss: 0.437260\nTrain Epoch: 8 [6400/26500 (24%)]\tLoss: 0.018201\nTrain Epoch: 8 [9600/26500 (36%)]\tLoss: 0.009790\nTrain Epoch: 8 [12800/26500 (48%)]\tLoss: 0.200854\nTrain Epoch: 8 [16000/26500 (60%)]\tLoss: 0.012838\nTrain Epoch: 8 [19200/26500 (72%)]\tLoss: 0.113933\nTrain Epoch: 8 [22400/26500 (84%)]\tLoss: 0.035034\nTrain Epoch: 8 [25600/26500 (97%)]\tLoss: 0.208797\nTrain Epoch: 9 [0/26500 (0%)]\tLoss: 0.017184\nTrain Epoch: 9 [3200/26500 (12%)]\tLoss: 0.039562\nTrain Epoch: 9 [6400/26500 (24%)]\tLoss: 0.377344\nTrain Epoch: 9 [9600/26500 (36%)]\tLoss: 0.010730\nTrain Epoch: 9 [12800/26500 (48%)]\tLoss: 0.139243\nTrain Epoch: 9 [16000/26500 (60%)]\tLoss: 0.002447\nTrain Epoch: 9 [19200/26500 (72%)]\tLoss: 0.008300\nTrain Epoch: 9 [22400/26500 (84%)]\tLoss: 0.011025\nTrain Epoch: 9 [25600/26500 (97%)]\tLoss: 0.036824\n\nTest set: Average loss: 0.0933, Accuracy: 6489/6626 (98%), AUROC: 0.8083\n\nTest loss:  0.09329167608684406\nAUROC:  0.8083245683491498\nFold:  2\nTrain Epoch: 0 [0/26501 (0%)]\tLoss: 1.580930\nTrain Epoch: 0 [3200/26501 (12%)]\tLoss: 0.478048\nTrain Epoch: 0 [6400/26501 (24%)]\tLoss: 0.124286\nTrain Epoch: 0 [9600/26501 (36%)]\tLoss: 0.006957\nTrain Epoch: 0 [12800/26501 (48%)]\tLoss: 0.106514\nTrain Epoch: 0 [16000/26501 (60%)]\tLoss: 0.010206\nTrain Epoch: 0 [19200/26501 (72%)]\tLoss: 0.024709\nTrain Epoch: 0 [22400/26501 (84%)]\tLoss: 0.410739\nTrain Epoch: 0 [25600/26501 (97%)]\tLoss: 0.435653\nTrain Epoch: 1 [0/26501 (0%)]\tLoss: 0.134015\nTrain Epoch: 1 [3200/26501 (12%)]\tLoss: 0.060519\nTrain Epoch: 1 [6400/26501 (24%)]\tLoss: 0.037479\nTrain Epoch: 1 [9600/26501 (36%)]\tLoss: 0.015250\nTrain Epoch: 1 [12800/26501 (48%)]\tLoss: 0.011402\nTrain Epoch: 1 [16000/26501 (60%)]\tLoss: 0.012519\nTrain Epoch: 1 [19200/26501 (72%)]\tLoss: 0.127822\nTrain Epoch: 1 [22400/26501 (84%)]\tLoss: 0.221599\nTrain Epoch: 1 [25600/26501 (97%)]\tLoss: 0.035098\nTrain Epoch: 2 [0/26501 (0%)]\tLoss: 0.006478\nTrain Epoch: 2 [3200/26501 (12%)]\tLoss: 0.246549\nTrain Epoch: 2 [6400/26501 (24%)]\tLoss: 0.016793\nTrain Epoch: 2 [9600/26501 (36%)]\tLoss: 0.145726\nTrain Epoch: 2 [12800/26501 (48%)]\tLoss: 0.038914\nTrain Epoch: 2 [16000/26501 (60%)]\tLoss: 0.017758\nTrain Epoch: 2 [19200/26501 (72%)]\tLoss: 0.169412\nTrain Epoch: 2 [22400/26501 (84%)]\tLoss: 0.029630\nTrain Epoch: 2 [25600/26501 (97%)]\tLoss: 0.114211\nTrain Epoch: 3 [0/26501 (0%)]\tLoss: 0.023169\nTrain Epoch: 3 [3200/26501 (12%)]\tLoss: 0.121100\nTrain Epoch: 3 [6400/26501 (24%)]\tLoss: 0.004047\nTrain Epoch: 3 [9600/26501 (36%)]\tLoss: 0.035023\nTrain Epoch: 3 [12800/26501 (48%)]\tLoss: 0.334516\nTrain Epoch: 3 [16000/26501 (60%)]\tLoss: 0.196120\nTrain Epoch: 3 [19200/26501 (72%)]\tLoss: 0.005513\nTrain Epoch: 3 [22400/26501 (84%)]\tLoss: 0.036493\nTrain Epoch: 3 [25600/26501 (97%)]\tLoss: 0.031568\nTrain Epoch: 4 [0/26501 (0%)]\tLoss: 0.277483\nTrain Epoch: 4 [3200/26501 (12%)]\tLoss: 0.046580\nTrain Epoch: 4 [6400/26501 (24%)]\tLoss: 0.156280\nTrain Epoch: 4 [9600/26501 (36%)]\tLoss: 0.006451\nTrain Epoch: 4 [12800/26501 (48%)]\tLoss: 0.085112\nTrain Epoch: 4 [16000/26501 (60%)]\tLoss: 0.015166\nTrain Epoch: 4 [19200/26501 (72%)]\tLoss: 0.007690\nTrain Epoch: 4 [22400/26501 (84%)]\tLoss: 0.030058\nTrain Epoch: 4 [25600/26501 (97%)]\tLoss: 0.133686\nTrain Epoch: 5 [0/26501 (0%)]\tLoss: 0.053394\nTrain Epoch: 5 [3200/26501 (12%)]\tLoss: 0.246042\nTrain Epoch: 5 [6400/26501 (24%)]\tLoss: 0.328042\nTrain Epoch: 5 [9600/26501 (36%)]\tLoss: 0.092839\nTrain Epoch: 5 [12800/26501 (48%)]\tLoss: 0.017218\nTrain Epoch: 5 [16000/26501 (60%)]\tLoss: 0.017953\nTrain Epoch: 5 [19200/26501 (72%)]\tLoss: 0.002717\nTrain Epoch: 5 [22400/26501 (84%)]\tLoss: 0.145417\nTrain Epoch: 5 [25600/26501 (97%)]\tLoss: 0.117405\nTrain Epoch: 6 [0/26501 (0%)]\tLoss: 0.014803\nTrain Epoch: 6 [3200/26501 (12%)]\tLoss: 0.106873\nTrain Epoch: 6 [6400/26501 (24%)]\tLoss: 0.009473\nTrain Epoch: 6 [9600/26501 (36%)]\tLoss: 0.014908\nTrain Epoch: 6 [12800/26501 (48%)]\tLoss: 0.023408\nTrain Epoch: 6 [16000/26501 (60%)]\tLoss: 0.207777\nTrain Epoch: 6 [19200/26501 (72%)]\tLoss: 0.022605\nTrain Epoch: 6 [22400/26501 (84%)]\tLoss: 0.019930\nTrain Epoch: 6 [25600/26501 (97%)]\tLoss: 0.037831\nTrain Epoch: 7 [0/26501 (0%)]\tLoss: 0.018122\nTrain Epoch: 7 [3200/26501 (12%)]\tLoss: 0.143446\nTrain Epoch: 7 [6400/26501 (24%)]\tLoss: 0.006112\nTrain Epoch: 7 [9600/26501 (36%)]\tLoss: 0.174286\nTrain Epoch: 7 [12800/26501 (48%)]\tLoss: 0.017381\nTrain Epoch: 7 [16000/26501 (60%)]\tLoss: 0.011230\nTrain Epoch: 7 [19200/26501 (72%)]\tLoss: 0.323490\nTrain Epoch: 7 [22400/26501 (84%)]\tLoss: 0.010263\nTrain Epoch: 7 [25600/26501 (97%)]\tLoss: 0.033300\nTrain Epoch: 8 [0/26501 (0%)]\tLoss: 0.040955\nTrain Epoch: 8 [3200/26501 (12%)]\tLoss: 0.371352\n","name":"stdout"},{"output_type":"stream","text":"Train Epoch: 8 [6400/26501 (24%)]\tLoss: 0.006368\nTrain Epoch: 8 [9600/26501 (36%)]\tLoss: 0.380614\nTrain Epoch: 8 [12800/26501 (48%)]\tLoss: 0.231013\nTrain Epoch: 8 [16000/26501 (60%)]\tLoss: 0.535803\nTrain Epoch: 8 [19200/26501 (72%)]\tLoss: 0.029590\nTrain Epoch: 8 [22400/26501 (84%)]\tLoss: 0.042992\nTrain Epoch: 8 [25600/26501 (97%)]\tLoss: 0.022863\nTrain Epoch: 9 [0/26501 (0%)]\tLoss: 0.015605\nTrain Epoch: 9 [3200/26501 (12%)]\tLoss: 0.006647\nTrain Epoch: 9 [6400/26501 (24%)]\tLoss: 0.018759\nTrain Epoch: 9 [9600/26501 (36%)]\tLoss: 0.006922\nTrain Epoch: 9 [12800/26501 (48%)]\tLoss: 0.013079\nTrain Epoch: 9 [16000/26501 (60%)]\tLoss: 0.063167\nTrain Epoch: 9 [19200/26501 (72%)]\tLoss: 0.096608\nTrain Epoch: 9 [22400/26501 (84%)]\tLoss: 0.008845\nTrain Epoch: 9 [25600/26501 (97%)]\tLoss: 0.219988\n\nTest set: Average loss: 0.0987, Accuracy: 6477/6625 (98%), AUROC: 0.7766\n\nTest loss:  0.09872204844119414\nAUROC:  0.7765666636646341\nFold:  3\nTrain Epoch: 0 [0/26501 (0%)]\tLoss: 2.716161\nTrain Epoch: 0 [3200/26501 (12%)]\tLoss: 0.349494\nTrain Epoch: 0 [6400/26501 (24%)]\tLoss: 0.293584\nTrain Epoch: 0 [9600/26501 (36%)]\tLoss: 0.057575\nTrain Epoch: 0 [12800/26501 (48%)]\tLoss: 0.103997\nTrain Epoch: 0 [16000/26501 (60%)]\tLoss: 0.020777\nTrain Epoch: 0 [19200/26501 (72%)]\tLoss: 0.172157\nTrain Epoch: 0 [22400/26501 (84%)]\tLoss: 0.096217\nTrain Epoch: 0 [25600/26501 (97%)]\tLoss: 0.291294\nTrain Epoch: 1 [0/26501 (0%)]\tLoss: 0.367118\nTrain Epoch: 1 [3200/26501 (12%)]\tLoss: 0.304772\nTrain Epoch: 1 [6400/26501 (24%)]\tLoss: 0.153839\nTrain Epoch: 1 [9600/26501 (36%)]\tLoss: 0.233968\nTrain Epoch: 1 [12800/26501 (48%)]\tLoss: 0.477235\nTrain Epoch: 1 [16000/26501 (60%)]\tLoss: 0.206191\nTrain Epoch: 1 [19200/26501 (72%)]\tLoss: 0.105734\nTrain Epoch: 1 [22400/26501 (84%)]\tLoss: 0.014144\nTrain Epoch: 1 [25600/26501 (97%)]\tLoss: 0.276348\nTrain Epoch: 2 [0/26501 (0%)]\tLoss: 0.003441\nTrain Epoch: 2 [3200/26501 (12%)]\tLoss: 0.024727\nTrain Epoch: 2 [6400/26501 (24%)]\tLoss: 0.009723\nTrain Epoch: 2 [9600/26501 (36%)]\tLoss: 0.011550\nTrain Epoch: 2 [12800/26501 (48%)]\tLoss: 0.162006\nTrain Epoch: 2 [16000/26501 (60%)]\tLoss: 0.001550\nTrain Epoch: 2 [19200/26501 (72%)]\tLoss: 0.005470\nTrain Epoch: 2 [22400/26501 (84%)]\tLoss: 0.003144\nTrain Epoch: 2 [25600/26501 (97%)]\tLoss: 0.012040\nTrain Epoch: 3 [0/26501 (0%)]\tLoss: 0.045998\nTrain Epoch: 3 [3200/26501 (12%)]\tLoss: 0.258649\nTrain Epoch: 3 [6400/26501 (24%)]\tLoss: 0.045110\nTrain Epoch: 3 [9600/26501 (36%)]\tLoss: 0.057095\nTrain Epoch: 3 [12800/26501 (48%)]\tLoss: 0.014517\nTrain Epoch: 3 [16000/26501 (60%)]\tLoss: 0.013742\nTrain Epoch: 3 [19200/26501 (72%)]\tLoss: 0.416798\nTrain Epoch: 3 [22400/26501 (84%)]\tLoss: 0.053588\nTrain Epoch: 3 [25600/26501 (97%)]\tLoss: 0.036441\nTrain Epoch: 4 [0/26501 (0%)]\tLoss: 0.161200\nTrain Epoch: 4 [3200/26501 (12%)]\tLoss: 0.015021\nTrain Epoch: 4 [6400/26501 (24%)]\tLoss: 0.055739\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make predictions for the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(network, test_loader):\n    network.eval()\n    \n    probs = np.zeros((len(test_loader.dataset)))\n    preds = np.zeros((len(test_loader.dataset)))\n    for i, data in enumerate(test_loader):  # return each batch\n        data = data.to(device)\n        \n        output = network(data)\n    \n        prob = F.softmax(output, 1)[:, 1].cpu().detach().numpy()\n        pred = output.data.max(1, keepdim=True)[1].flatten().cpu().detach().numpy() # get the index of the max log-probability\n        \n        probs[i*batch_size:(i+1)*batch_size] = prob\n        preds[i*batch_size:(i+1)*batch_size] = pred\n        \n    return probs, preds    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load all of the trained models\nmodel1 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\nmodel1.load_state_dict(torch.load(\"./enet1.pt\"))\nmodel1.cuda()\n\nmodel2 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\nmodel2.load_state_dict(torch.load(\"./enet2.pt\"))\nmodel2.cuda()\n\nmodel3 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\nmodel3.load_state_dict(torch.load(\"./enet3.pt\"))\nmodel3.cuda()\n\nmodel4 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\nmodel4.load_state_dict(torch.load(\"./enet4.pt\"))\nmodel4.cuda()\n\n\nmodel5 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=2)\nmodel5.load_state_dict(torch.load(\"./enet5.pt\"))\nmodel5.cuda()\n\n\ntestset = MyDataset(test_df, train=False, transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\np1, _ = predict(model1, test_loader)\np2, _ = predict(model2, test_loader)\np3, _ = predict(model3, test_loader)\np4, _ = predict(model4, test_loader)\np5, _ = predict(model5, test_loader)\nprobs = (p1 + p2 + p3 + p4 + p5) / 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble the models into a single model\nclass MyEnsemble(nn.Module):\n    def __init__(self, model1, model2, model3, model4, model5):\n        super(MyEnsemble, self).__init__()\n        self.model1 = model1\n        self.model2 = model2\n        self.model3 = model3\n        self.model4 = model4\n        self.model5 = model5\n        self.classifier = nn.Linear(10, 2)\n        \n    def forward(self, img):\n        x1 = self.model1(img)\n        x2 = self.model2(img)\n        x3 = self.model3(img)\n        x4 = self.model4(img)\n        x5 = self.model5(img)\n        \n        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n        x = self.classifier(F.relu(x))\n        return x\n        \nmodel = MyEnsemble(model1, model2, model3, model4, model5)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for the test_values\n# probs, preds = predict(network, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write to file\nsubmission = pd.DataFrame({'image_name': test_df['image_name'], 'target': probs})\n\nsubmission.to_csv('enet.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get evaluation metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# make evaluations on all the training data\ntest_loss, test_acc, test_roc = test(network, train_loader)  # print the validation error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Store Trained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the model\nPATH = \"enet.pt\"\ntorch.save(network.state_dict(), PATH)  # we only save the state_dict rather than entire model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model and use for evaluation\nnetwork = MultiLayerNet(num_inputs, num_outputs, hidden_units=1000)\n#model.load_state_dict(\"../output/\" + torch.load(PATH)) \nnetwork.load_state_dict(torch.load(\"../input/multilayer-model/multilayer.pt\")) \nnetwork.eval()  # set dropout and batch normalization layers to evaluation before running inference","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting for a Single Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_single_image(image):\n    \"\"\"Given an image, predict benign or malignant \"\"\"\n    network.eval()\n    \n    for i, data in enumerate(test_loader):  # return each batch\n        output = network(data)\n    \n        prob = F.softmax(output)[:, 1].item()\n        pred = output.data.max(1, keepdim=True)[1].flatten().item() # get the index of the max log-probability\n        \n    return prob, pred","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}